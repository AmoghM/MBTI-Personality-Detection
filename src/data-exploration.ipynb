{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/Reddit-19K personality data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 100000\n",
    "mbti_comments = pd.read_csv(data_path+\"mbti9k_comments.csv\",chunksize=chunksize)\n",
    "typed_comments = pd.read_csv(data_path+\"typed_comments.csv\",chunksize=chunksize)\n",
    "# typed_posts = pd.read_csv(data_path+\"typed_posts.csv\",chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>type</th>\n",
       "      <th>subreddits_commented</th>\n",
       "      <th>mbti_subreddits_commented</th>\n",
       "      <th>wc</th>\n",
       "      <th>comments_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--asmodeus--</td>\n",
       "      <td>Yes! Personally I feel that as helpful as it i...</td>\n",
       "      <td>entp</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1367</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--hypnos--</td>\n",
       "      <td>I guess I'd stick to being a lesbian so I woul...</td>\n",
       "      <td>intj</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>28328</td>\n",
       "      <td>1503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-Afrodisiac-</td>\n",
       "      <td>What languages do you speak? Whoops, my bad fo...</td>\n",
       "      <td>intp</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "      <td>13134</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-Automaticity</td>\n",
       "      <td>It is just arguing semantics. To many on the c...</td>\n",
       "      <td>entp</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>3724</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-Avacyn</td>\n",
       "      <td>Come to Europe if you're interested. In many E...</td>\n",
       "      <td>entj</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>123720</td>\n",
       "      <td>1297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author                                            comment  type  \\\n",
       "0   --asmodeus--  Yes! Personally I feel that as helpful as it i...  entp   \n",
       "1     --hypnos--  I guess I'd stick to being a lesbian so I woul...  intj   \n",
       "2   -Afrodisiac-  What languages do you speak? Whoops, my bad fo...  intp   \n",
       "3  -Automaticity  It is just arguing semantics. To many on the c...  entp   \n",
       "4        -Avacyn  Come to Europe if you're interested. In many E...  entj   \n",
       "\n",
       "   subreddits_commented  mbti_subreddits_commented      wc  comments_num  \n",
       "0                     6                          1    1367            38  \n",
       "1                    49                          1   28328          1503  \n",
       "2                    78                          8   13134           611  \n",
       "3                    33                          2    3724           117  \n",
       "4                    67                          2  123720          1297  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbti_comments.get_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "\"ISTJ\":1,\n",
    "\"ISTP\":2,\n",
    "\"ISFJ\":3,\n",
    "\"ISFP\":4,\n",
    "\"INFJ\":5,\n",
    "\"INFP\":6,\n",
    "\"INTJ\":7,\n",
    "\"INTP\":8,\n",
    "\"ESTP\":9,\n",
    "\"ESTJ\":10,\n",
    "\"ESFP\":11,\n",
    "\"ESFJ\":12,\n",
    "\"ENFP\":13,\n",
    "\"ENFJ\":14,\n",
    "\"ENTP\":15,\n",
    "\"ENTJ\":16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>downs</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>score</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>...</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>ups</th>\n",
       "      <th>type</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_count_quoteless</th>\n",
       "      <th>quote_to_text_ratio</th>\n",
       "      <th>is_mbti_related</th>\n",
       "      <th>comment</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MetricExpansion</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.474429e+09</td>\n",
       "      <td>t5_2s90r</td>\n",
       "      <td>t3_53plrw</td>\n",
       "      <td>t3_53plrw</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>d7vkyrf</td>\n",
       "      <td>mbti</td>\n",
       "      <td>6.0</td>\n",
       "      <td>entp</td>\n",
       "      <td>151</td>\n",
       "      <td>149</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>True</td>\n",
       "      <td>Those stats come from the test. [Echoing the c...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MetricExpansion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.480139e+09</td>\n",
       "      <td>t5_2s90r</td>\n",
       "      <td>t3_5ep948</td>\n",
       "      <td>t1_dafz6ab</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>dafzzrg</td>\n",
       "      <td>mbti</td>\n",
       "      <td>0.0</td>\n",
       "      <td>entp</td>\n",
       "      <td>319</td>\n",
       "      <td>316</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>True</td>\n",
       "      <td>That's great to hear! I hope you know that, de...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MetricExpansion</td>\n",
       "      <td>[ENTP-5 M 22]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.455096e+09</td>\n",
       "      <td>t5_2s90r</td>\n",
       "      <td>t3_44q2vf</td>\n",
       "      <td>t1_cztchk3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>czul5ag</td>\n",
       "      <td>mbti</td>\n",
       "      <td>1.0</td>\n",
       "      <td>entp</td>\n",
       "      <td>145</td>\n",
       "      <td>143</td>\n",
       "      <td>0.013793</td>\n",
       "      <td>True</td>\n",
       "      <td>I can totally agree on reticence! With respect...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MetricExpansion</td>\n",
       "      <td>&lt;U+1D07&gt;&lt;U+0274&gt;&lt;U+1D1B&gt;&lt;U+1D18&gt; - &lt;U+1D1B&gt;&lt;U+...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.462865e+09</td>\n",
       "      <td>t5_2s90r</td>\n",
       "      <td>t3_4ijf4l</td>\n",
       "      <td>t3_4ijf4l</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>d2zo611</td>\n",
       "      <td>mbti</td>\n",
       "      <td>1.0</td>\n",
       "      <td>entp</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>I took it several times. I'm typed as TYPE_MEN...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MetricExpansion</td>\n",
       "      <td>&lt;U+1D07&gt;&lt;U+0274&gt;&lt;U+1D1B&gt;&lt;U+1D18&gt; - &lt;U+1D1B&gt;&lt;U+...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.460656e+09</td>\n",
       "      <td>t5_2s90r</td>\n",
       "      <td>t3_4eptxr</td>\n",
       "      <td>t1_d22uh4r</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>d22uu81</td>\n",
       "      <td>mbti</td>\n",
       "      <td>1.0</td>\n",
       "      <td>entp</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>Gawd it's like we don't even need drugs to be ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   name           author                                  author_flair_text  \\\n",
       "0   NaN  MetricExpansion                                               ENTP   \n",
       "1   NaN  MetricExpansion                                                NaN   \n",
       "2   NaN  MetricExpansion                                      [ENTP-5 M 22]   \n",
       "3   NaN  MetricExpansion  <U+1D07><U+0274><U+1D1B><U+1D18> - <U+1D1B><U+...   \n",
       "4   NaN  MetricExpansion  <U+1D07><U+0274><U+1D1B><U+1D18> - <U+1D1B><U+...   \n",
       "\n",
       "   downs   created_utc subreddit_id    link_id   parent_id  score  \\\n",
       "0    0.0  1.474429e+09     t5_2s90r  t3_53plrw   t3_53plrw    6.0   \n",
       "1    0.0  1.480139e+09     t5_2s90r  t3_5ep948  t1_dafz6ab    1.0   \n",
       "2    0.0  1.455096e+09     t5_2s90r  t3_44q2vf  t1_cztchk3    1.0   \n",
       "3    0.0  1.462865e+09     t5_2s90r  t3_4ijf4l   t3_4ijf4l    1.0   \n",
       "4    0.0  1.460656e+09     t5_2s90r  t3_4eptxr  t1_d22uh4r    1.0   \n",
       "\n",
       "   controversiality  ...       id subreddit  ups  type word_count  \\\n",
       "0               0.0  ...  d7vkyrf      mbti  6.0  entp        151   \n",
       "1               0.0  ...  dafzzrg      mbti  0.0  entp        319   \n",
       "2               0.0  ...  czul5ag      mbti  1.0  entp        145   \n",
       "3               0.0  ...  d2zo611      mbti  1.0  entp         41   \n",
       "4               0.0  ...  d22uu81      mbti  1.0  entp         11   \n",
       "\n",
       "   word_count_quoteless  quote_to_text_ratio  is_mbti_related  \\\n",
       "0                   149             0.013245             True   \n",
       "1                   316             0.009404             True   \n",
       "2                   143             0.013793             True   \n",
       "3                    41             0.000000             True   \n",
       "4                    11             0.000000             True   \n",
       "\n",
       "                                             comment lang  \n",
       "0  Those stats come from the test. [Echoing the c...   en  \n",
       "1  That's great to hear! I hope you know that, de...   en  \n",
       "2  I can totally agree on reticence! With respect...   en  \n",
       "3  I took it several times. I'm typed as TYPE_MEN...   en  \n",
       "4  Gawd it's like we don't even need drugs to be ...   en  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typed_comments.get_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>title</th>\n",
       "      <th>...</th>\n",
       "      <th>archived</th>\n",
       "      <th>is_self</th>\n",
       "      <th>from_id</th>\n",
       "      <th>permalink</th>\n",
       "      <th>name</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>quarantine</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1478473439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>userdna45</td>\n",
       "      <td>pepe.me</td>\n",
       "      <td>http://pepe.me</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brand your reddit post with the prestigious \"p...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/comments/5bipct/brand_your_reddit_post_with_t...</td>\n",
       "      <td>t3_5bipct</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1461925261</td>\n",
       "      <td>Libertarian</td>\n",
       "      <td>userdna45</td>\n",
       "      <td>dnaforce.ca</td>\n",
       "      <td>http://www.dnaforce.ca/article/weird-school-re...</td>\n",
       "      <td>187</td>\n",
       "      <td>77</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The horrors of common core state education: Te...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/r/Libertarian/comments/4gyrhd/the_horrors_of_...</td>\n",
       "      <td>t3_4gyrhd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1461884955</td>\n",
       "      <td>Anarcho_Capitalism</td>\n",
       "      <td>userdna45</td>\n",
       "      <td>dnaforce.ca</td>\n",
       "      <td>http://www.dnaforce.ca/article/weird-school-re...</td>\n",
       "      <td>164</td>\n",
       "      <td>105</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The horrors of common core state education: Te...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/r/Anarcho_Capitalism/comments/4gwntz/the_horr...</td>\n",
       "      <td>t3_4gwntz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1478480859</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>userdna45</td>\n",
       "      <td>youtube.com</td>\n",
       "      <td>https://www.youtube.com/watch?v=FKWmip6yZBs</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CNN Right now: Advanced software filtered out ...</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/r/The_Donald/comments/5bjbxw/cnn_right_now_ad...</td>\n",
       "      <td>t3_5bjbxw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1478441206</td>\n",
       "      <td>The_Donald</td>\n",
       "      <td>userdna45</td>\n",
       "      <td>wikileaks.org</td>\n",
       "      <td>https://wikileaks.org/podesta-emails/emailid/5...</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>WTF?? Clintons blackmailing their own daughter?</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/r/The_Donald/comments/5bfvbf/wtf_clintons_bla...</td>\n",
       "      <td>t3_5bfvbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>intj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_utc           subreddit     author         domain  \\\n",
       "0   1478473439                 NaN  userdna45        pepe.me   \n",
       "1   1461925261         Libertarian  userdna45    dnaforce.ca   \n",
       "2   1461884955  Anarcho_Capitalism  userdna45    dnaforce.ca   \n",
       "3   1478480859          The_Donald  userdna45    youtube.com   \n",
       "4   1478441206          The_Donald  userdna45  wikileaks.org   \n",
       "\n",
       "                                                 url  num_comments  score  \\\n",
       "0                                     http://pepe.me            20     27   \n",
       "1  http://www.dnaforce.ca/article/weird-school-re...           187     77   \n",
       "2  http://www.dnaforce.ca/article/weird-school-re...           164    105   \n",
       "3        https://www.youtube.com/watch?v=FKWmip6yZBs             4     27   \n",
       "4  https://wikileaks.org/podesta-emails/emailid/5...             1     33   \n",
       "\n",
       "     ups  downs                                              title  ...  \\\n",
       "0   27.0    0.0  Brand your reddit post with the prestigious \"p...  ...   \n",
       "1   77.0    0.0  The horrors of common core state education: Te...  ...   \n",
       "2  105.0    0.0  The horrors of common core state education: Te...  ...   \n",
       "3   27.0    0.0  CNN Right now: Advanced software filtered out ...  ...   \n",
       "4   33.0    0.0    WTF?? Clintons blackmailing their own daughter?  ...   \n",
       "\n",
       "   archived  is_self from_id  \\\n",
       "0     False    False     NaN   \n",
       "1     False    False     NaN   \n",
       "2     False    False     NaN   \n",
       "3     False    False     NaN   \n",
       "4     False    False     NaN   \n",
       "\n",
       "                                           permalink       name  \\\n",
       "0  /comments/5bipct/brand_your_reddit_post_with_t...  t3_5bipct   \n",
       "1  /r/Libertarian/comments/4gyrhd/the_horrors_of_...  t3_4gyrhd   \n",
       "2  /r/Anarcho_Capitalism/comments/4gwntz/the_horr...  t3_4gwntz   \n",
       "3  /r/The_Donald/comments/5bjbxw/cnn_right_now_ad...  t3_5bjbxw   \n",
       "4  /r/The_Donald/comments/5bfvbf/wtf_clintons_bla...  t3_5bfvbf   \n",
       "\n",
       "   author_flair_text  quarantine  link_flair_text  distinguished  type  \n",
       "0                NaN       False              NaN            NaN  intj  \n",
       "1                NaN       False              NaN            NaN  intj  \n",
       "2                NaN       False              NaN            NaN  intj  \n",
       "3                NaN       False              NaN            NaN  intj  \n",
       "4                NaN       False              NaN            NaN  intj  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typed_posts.get_chunk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in mbti_comments.iterrows():\n",
    "    data.append({\"text\":str(row['comment']),\"label\":row['type']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_data(typed_comments)\n",
    "random.shuffle(data)\n",
    "train, test  = data[:int(len(data)*0.8)], data[int(len(data)*0.8):]\n",
    "random.shuffle(train)\n",
    "random.shuffle(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_data_json(\"../data/typed_comments/train_clean_.json\",train,100000)\n",
    "export_data_json(\"../data/typed_comments/test_clean_.json\",test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9252\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "data_mbti = generate_data(mbti_comments)\n",
    "random.shuffle(data_mbti)\n",
    "print(len(data_mbti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "train_mbti = data_mbti[:int(len(data_mbti)*0.8)]\n",
    "export_data_json(\"../data/mbti_comments/train_clean_.json\",train_mbti,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "test_mbti = data_mbti[int(len(data_mbti)*0.8):]\n",
    "export_data_json(\"../data/mbti_comments/test_clean.json\",test_mbti,100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data_json(path,data,breakpoint=1000):\n",
    "    with open(path,\"a+\",encoding=\"utf-8\") as fw:\n",
    "        for idx, row in enumerate(data):\n",
    "            row[\"text\"] = cleaning(row[\"text\"])\n",
    "            if idx%1000==0:\n",
    "                print(idx)\n",
    "            if idx > breakpoint:\n",
    "                break\n",
    "            json.dump(row, fw)\n",
    "            fw.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    return clean(text,\n",
    "    fix_unicode=True,               # fix various unicode errors\n",
    "    to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "    lower=True,                     # lowercase text\n",
    "    no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\n",
    "    no_urls=True,                  # replace all URLs with a special token\n",
    "    no_emails=True,                # replace all email addresses with a special token\n",
    "    no_phone_numbers=True,         # replace all phone numbers with a special token\n",
    "    no_numbers=True,               # replace all numbers with a special token\n",
    "    no_digits=True,                # replace all digits with a special token\n",
    "    no_currency_symbols=True,      # replace all currency symbols with a special token\n",
    "    no_punct=True,                 # fully remove punctuation\n",
    "    replace_with_url=\"<URL>\",\n",
    "    replace_with_email=\"<EMAIL>\",\n",
    "    replace_with_phone_number=\"<PHONE>\",\n",
    "    replace_with_number=\"<NUMBER>\",\n",
    "    replace_with_digit=\"0\",\n",
    "    replace_with_currency_symbol=\"<CUR>\",\n",
    "    lang=\"en\"                       # set to 'de' for German special handling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(dataframe):\n",
    "    count=0\n",
    "    data = []\n",
    "    for chunk in dataframe:\n",
    "        comment = chunk['comment']\n",
    "        label = chunk['type']\n",
    "        for i,j in zip(comment,label):\n",
    "            if len(i.split()) > 10:\n",
    "                data.append({\"text\":str(i),\"label\":j})\n",
    "                count+=1\n",
    "        if count%10000==0:\n",
    "            print(count/10000)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_json_to_csv(data,write_path,labels,header=False):\n",
    "    df_data = pd.DataFrame.from_dict(data, orient='columns')\n",
    "    df_data = df_data[['label','text']]\n",
    "    for label in labels:\n",
    "        key = label.lower()\n",
    "        df_data = df_data.replace(key,labels[label])\n",
    "    return df_data.to_csv(write_path,index=False,encoding=\"utf-8\",header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_json_to_csv(train[:20000],\"../data/typed_comments/train.csv\",labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_json_to_csv(test[:5000],\"../data/typed_comments/test.csv\",labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7401"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_mbti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'the not taking up a slot thing sounds like some sheltered friends in high school that told me i shouldnt shop at goodwill because that takes away clothes that were meant for poor people to buy it was a whole not getting it at a level where its gonna take a few extra steps to come to any agreement',\n",
       " 'label': 'intp'}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mbti[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9252"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_mbti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7401.6"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8 * len(data_mbti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_mbti[int(0.8 * len(data_mbti)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Welcome to the sub, I'm Sam  one of the mods, and we hope you love it here!I checked your flair and wishlist and everything looks great - nice work!Please make sure you check out our [User Guide](https://www.reddit.com/r/Random_Acts_Of_Amazon/wiki/userguide#/button/c/blue/randomlist), and our [Rules.](https://www.reddit.com/r/Random_Acts_Of_Amazon/wiki/rules#/button/c/blue/randomlist)Our stickied post on the main page is the Daily/Nightly Chat threads (posted every 12 hours) where people sort by /new and play day and night! Be sure to check them out. There is also an Adopt-a-newbie activity posted weekly you should check out - these can usually be found in the header of the sub so you can find them easily every day!Feel free to let me know if you have any questions, we want you to feel at home!:)\",\n",
       " 'label': 'istp'}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7401"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_mbti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_json_to_csv(train_mbti,\"../data/mbti_comments/train_.csv\",labels)\n",
    "convert_json_to_csv(test_mbti,\"../data/mbti_comments/test_.csv\",labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
