{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# import stuff\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from random import randint\n",
    "import numpy as np\n",
    "import torch\n",
    "from numpy import save\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import InferSent\n",
    "V = 2\n",
    "MODEL_PATH = 'encoder/infersent%s.pkl' % V\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
    "\n",
    "model = InferSent(params_model)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./fastText/crawl-300d-2M.vec'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2V_PATH = \"./fastText/crawl-300d-2M.vec\"\n",
    "W2V_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_w2v_path(W2V_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size : 100000\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab_k_words(K=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/amoghmishra23/appledore/MBTI-Personality-Detection/data/mbti_comments/mbti_comments_cleaned.csv',chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9248"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = []\n",
    "for chunk in df:\n",
    "    text = text + chunk['comment'].tolist()\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb words kept : 999/1019 (98.0%)\n",
      "Speed : 3.9 sentences/s (gpu mode, bsize=128)\n",
      "nb sentences encoded : 1\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode([text[0]], bsize=128, tokenize=False, verbose=True)\n",
    "print('nb sentences encoded : {0}'.format(len(embeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_idx = []\n",
    "with open('output/embedding_infersent.txt','w+') as fw:\n",
    "    for i in range(0,len(text)):\n",
    "        try:\n",
    "            embeddings = model.encode([text[i]], bsize=64, tokenize=False, verbose=True).tolist()[0]\n",
    "            torch.cuda.empty_cache()\n",
    "        except RuntimeError:\n",
    "            error_idx.append(i)\n",
    "        \n",
    "        fw.write(str(embeddings)+\"\\n\")\n",
    "        if i%10==0:\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoding = { \"istj\":1, \"istp\":2, \"isfj\":3, \"isfp\":4, \"infj\":5, \"infp\":6, \"intj\":7, \"intp\":8, \"estp\":9, \"estj\":10, \"esfp\":11, \"esfj\":12, \"enfp\":13, \"enfj\":14, \"entp\":15, \"entj\":16 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferesent_embedding(path,text,label,batch=64):\n",
    "    error_idx = []\n",
    "    count= 0\n",
    "    with open(path,'w+') as fw:\n",
    "        for i,j in zip(text,label):\n",
    "            try:\n",
    "                print(count)\n",
    "                embeddings = model.encode([i], bsize=512, tokenize=False, verbose=True).tolist()[0]\n",
    "#                 torch.cuda.empty_cache()\n",
    "                data = {\"label\":j-1, \"embedding\": embeddings}\n",
    "                json.dump(data, fw)\n",
    "                fw.write(\"\\n\")\n",
    "            except RuntimeError:\n",
    "                error_idx.append(i)\n",
    "            count+=1\n",
    "#             if count%1000 == 0:\n",
    "#                 print(\"===========\",count%1000,\"==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    df = pd.read_csv(path,header=None)    \n",
    "    return df[0].tolist(),df[1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/amoghmishra23/appledore/MBTI-Personality-Detection/data/mbti_comments/extra_clean_seq_60.csv\"\n",
    "text, label = read_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferesent_embedding(\"output/embedding_extra_clean_seq_60.json\",text,label,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
